#!/usr/bin/env python3
"""
GSM8K æ€§èƒ½ä¼˜åŒ–é…ç½®
ä¸“é—¨ç”¨äºæé«˜GPUåˆ©ç”¨ç‡å’Œè®­ç»ƒé€Ÿåº¦
"""

from dataclasses import dataclass
from typing import List, Optional

@dataclass
class HighPerformanceConfig:
    """é«˜æ€§èƒ½è®­ç»ƒé…ç½® - ä¼˜åŒ–GPUåˆ©ç”¨ç‡"""
    
    # æ¨¡å‹é…ç½®
    model_name: str = "Qwen/Qwen3-30B-A3B-Instruct-2507"
    
    # æ•°æ®é…ç½®
    dataset_name: str = "gsm8k"
    dataset_config: str = "main"
    max_length: int = 1024
    train_split: float = 0.9
    
    # LoRAé…ç½® - å¹³è¡¡æ€§èƒ½å’Œå†…å­˜
    lora_r: int = 64
    lora_alpha: int = 128
    lora_dropout: float = 0.05  # é™ä½dropoutä»¥æé«˜é€Ÿåº¦
    target_modules: List[str] = None
    
    # è®­ç»ƒé…ç½® - ä¼˜åŒ–GPUåˆ©ç”¨ç‡ï¼ŒåŒæ—¶æ§åˆ¶å†…å­˜ä½¿ç”¨
    num_epochs: int = 3
    per_device_train_batch_size: int = 2  # å°æ‰¹æ¬¡å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
    per_device_eval_batch_size: int = 2
    gradient_accumulation_steps: int = 8  # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¥æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡
    learning_rate: float = 5e-4  # ç¨é«˜çš„å­¦ä¹ ç‡
    warmup_steps: int = 50  # å‡å°‘warmupæ­¥æ•°
    max_grad_norm: float = 1.0
    
    # ç”Ÿæˆé…ç½®
    max_new_tokens: int = 512
    temperature: float = 0.7
    top_p: float = 0.9
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "./gsm8k_high_perf"
    logging_dir: str = "./logs"
    save_total_limit: int = 2
    
    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    fp16: bool = True
    dataloader_num_workers: int = 4  # é€‚ä¸­çš„æ•°æ®åŠ è½½çº¿ç¨‹
    dataloader_pin_memory: bool = True  # å¯ç”¨å†…å­˜é”å®š
    gradient_checkpointing: bool = True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜
    
    def __post_init__(self):
        if self.target_modules is None:
            self.target_modules = [
                "q_proj", "k_proj", "v_proj", "o_proj",
                "gate_proj", "up_proj", "down_proj"
            ]

@dataclass
class GPUOptimizedConfig:
    """GPUä¼˜åŒ–é…ç½® - é’ˆå¯¹é«˜GPUåˆ©ç”¨ç‡"""
    
    # æ¨¡å‹é…ç½®
    model_name: str = "Qwen/Qwen3-30B-A3B-Instruct-2507"
    
    # æ•°æ®é…ç½®
    dataset_name: str = "gsm8k"
    dataset_config: str = "main"
    max_length: int = 768  # ç¨çŸ­çš„åºåˆ—é•¿åº¦ä»¥æé«˜ååé‡
    train_split: float = 0.9
    
    # LoRAé…ç½®
    lora_r: int = 32  # è¾ƒå°çš„ç§©ä»¥æé«˜é€Ÿåº¦
    lora_alpha: int = 64
    lora_dropout: float = 0.05
    target_modules: List[str] = None
    
    # è®­ç»ƒé…ç½® - å¹³è¡¡GPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨
    num_epochs: int = 3
    per_device_train_batch_size: int = 1  # æœ€å°æ‰¹æ¬¡å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
    per_device_eval_batch_size: int = 1
    gradient_accumulation_steps: int = 16  # ä½¿ç”¨å¤§é‡æ¢¯åº¦ç´¯ç§¯æ¥æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡
    learning_rate: float = 8e-4  # æ›´é«˜çš„å­¦ä¹ ç‡
    warmup_steps: int = 30
    max_grad_norm: float = 1.0
    
    # ç³»ç»Ÿé…ç½®
    max_new_tokens: int = 384  # å‡å°‘ç”Ÿæˆé•¿åº¦
    temperature: float = 0.7
    top_p: float = 0.9
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "./gsm8k_gpu_opt"
    logging_dir: str = "./logs"
    save_total_limit: int = 1  # å‡å°‘ä¿å­˜é¢‘ç‡
    
    # æ€§èƒ½é…ç½®
    fp16: bool = True
    dataloader_num_workers: int = 4  # é€‚ä¸­çš„æ•°æ®åŠ è½½çº¿ç¨‹
    dataloader_pin_memory: bool = True
    gradient_checkpointing: bool = True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜
    
    def __post_init__(self):
        if self.target_modules is None:
            # åªè®­ç»ƒå…³é”®æ¨¡å—ä»¥æé«˜é€Ÿåº¦
            self.target_modules = ["q_proj", "v_proj", "o_proj"]

@dataclass
class MemoryEfficientConfig:
    """å†…å­˜é«˜æ•ˆé…ç½® - åœ¨æœ‰é™å†…å­˜ä¸‹æœ€å¤§åŒ–æ€§èƒ½"""
    
    # æ¨¡å‹é…ç½®
    model_name: str = "Qwen/Qwen3-30B-A3B-Instruct-2507"
    
    # æ•°æ®é…ç½®
    dataset_name: str = "gsm8k"
    dataset_config: str = "main"
    max_length: int = 512  # è¾ƒçŸ­çš„åºåˆ—é•¿åº¦
    train_split: float = 0.9
    
    # LoRAé…ç½®
    lora_r: int = 16  # æœ€å°çš„ç§©
    lora_alpha: int = 32
    lora_dropout: float = 0.1
    target_modules: List[str] = None
    
    # è®­ç»ƒé…ç½®
    num_epochs: int = 3
    per_device_train_batch_size: int = 4  # é€‚ä¸­çš„æ‰¹æ¬¡å¤§å°
    per_device_eval_batch_size: int = 4
    gradient_accumulation_steps: int = 4  # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
    learning_rate: float = 3e-4
    warmup_steps: int = 100
    max_grad_norm: float = 1.0
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "./gsm8k_memory_efficient"
    logging_dir: str = "./logs"
    save_total_limit: int = 2
    
    # å†…å­˜ä¼˜åŒ–é…ç½®
    fp16: bool = True
    dataloader_num_workers: int = 4
    dataloader_pin_memory: bool = True
    gradient_checkpointing: bool = True  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜

    def __post_init__(self):
        if self.target_modules is None:
            self.target_modules = ["q_proj", "v_proj"]

# æ€§èƒ½ä¼˜åŒ–è®­ç»ƒå‚æ•°
PERFORMANCE_TRAINING_ARGS = {
    "logging_steps": 1,  # æ›´é¢‘ç¹çš„æ—¥å¿—è®°å½•ä»¥ç›‘æ§GPUåˆ©ç”¨ç‡
    "eval_steps": 25,    # æ›´é¢‘ç¹çš„è¯„ä¼°
    "save_steps": 100,   # æ›´é¢‘ç¹çš„ä¿å­˜
    "save_total_limit": 1,  # å‡å°‘ç£ç›˜I/O
    "load_best_model_at_end": False,
    "metric_for_best_model": "eval_loss",
    "greater_is_better": False,
    "report_to": "tensorboard",
    "fp16": True,
    "dataloader_num_workers": 8,
    "remove_unused_columns": False,
    "dataloader_pin_memory": True,
    "gradient_checkpointing": False,
}

def get_performance_config(config_type: str = "high_perf", model_name: str = None):
    """è·å–æ€§èƒ½ä¼˜åŒ–é…ç½®"""
    configs = {
        "high_perf": HighPerformanceConfig,
        "gpu_opt": GPUOptimizedConfig,
        "memory_efficient": MemoryEfficientConfig,
    }
    
    config_class = configs.get(config_type, HighPerformanceConfig)
    
    if model_name:
        return config_class(model_name=model_name)
    else:
        return config_class()

def print_performance_tips():
    """æ‰“å°æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    print("ğŸ”§ GPUæ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("1. å¢å¤§æ‰¹æ¬¡å¤§å° (per_device_train_batch_size)")
    print("2. å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹ (dataloader_num_workers)")
    print("3. å¯ç”¨å†…å­˜é”å®š (dataloader_pin_memory=True)")
    print("4. ä½¿ç”¨FP16è®­ç»ƒ (fp16=True)")
    print("5. å‡å°‘åºåˆ—é•¿åº¦ (max_length)")
    print("6. ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (gradient_checkpointing=False)")
    print("7. å‡å°‘ä¿å­˜é¢‘ç‡ (save_steps, save_total_limit)")
    print("8. ä½¿ç”¨è¾ƒå°çš„LoRAç§© (lora_r)")
    print("\nğŸ“Š ç›‘æ§GPUåˆ©ç”¨ç‡:")
    print("nvidia-smi dmon -s pucvmet")

if __name__ == "__main__":
    print_performance_tips()
    
    print("\nğŸ“‹ å¯ç”¨é…ç½®:")
    for name, config_class in [
        ("high_perf", HighPerformanceConfig),
        ("gpu_opt", GPUOptimizedConfig),
        ("memory_efficient", MemoryEfficientConfig),
    ]:
        config = config_class()
        print(f"\n{name}:")
        print(f"  æ‰¹æ¬¡å¤§å°: {config.per_device_train_batch_size}")
        print(f"  åºåˆ—é•¿åº¦: {config.max_length}")
        print(f"  LoRAç§©: {config.lora_r}")
        print(f"  æ•°æ®åŠ è½½çº¿ç¨‹: {config.dataloader_num_workers}")